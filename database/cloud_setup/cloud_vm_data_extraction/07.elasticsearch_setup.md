<!--Just yesterday, I learnt that using a relational database managmeent system isnt the best choice for managing application logs and a time series databases exist for this reason. So, I will now create a separate database to collect application logs. I will be using elasticsearch server engine, and for data visualization, I will primairly use Grafana for system level metrics, and then use Tableau/PowerBI for business level metrics-->

# Elasticsearch 9.0.1 Installation & Reverse SSH Tunnel Setup

This guide describes how to install Elasticsearch 9.0.1 locally on Windows, and how to make it accessible from a remote Ubuntu VM using a reverse SSH tunnel. It also covers automating the startup of both Elasticsearch and the tunnel in the background using Task Scheduler.

---

## Overview

- **Purpose:** Collect application logs using Elasticsearch, visualize system metrics with Grafana, and business metrics with Tableau/PowerBI.
- **Setup:** Local Elasticsearch on Windows, accessible from a remote Ubuntu VM via reverse SSH tunnel.

---

## System Requirements

- Operating System: Windows 11, macOS Ventura, Ubuntu 22.04, etc.
- Java: Bundled with Elasticsearch 9.0.1
- Recommended RAM: Minimum 4GB

---

## Step 1: Download & Install Elasticsearch

1. Download from: https://www.elastic.co/downloads/elasticsearch  
   (e.g., `elasticsearch-9.0.1-windows-x86_64.zip`)
2. Extract to: `C:\Elastic\elasticsearch-9.0.1` (or your preferred directory)

---

## Step 2: Start Elasticsearch

1. Open a terminal or PowerShell window.
2. Change directory to the `bin` folder:
   ```cmd
   cd C:\Elastic\elasticsearch-9.0.1\bin
   .\elasticsearch.bat
   ```
3. On first startup, note the generated `elastic` user password.

> Elasticsearch 9.x+ starts with security enabled (HTTPS, authentication).

---

## Step 3: Access Elasticsearch

- URL: https://localhost:9200
- Use your browser or an API client (e.g., Postman, curl).
- Default username: `elastic`
- Password: Shown in terminal on first startup.

Example verification:

```cmd
curl -k -u elastic:<your-password> https://localhost:9200
```

Expected: JSON response with cluster info.

---

## Step 4: Set Up Reverse SSH Tunnel (Windows → Ubuntu VM)

This allows your Ubuntu VM to access Elasticsearch running on your Windows machine.

### Batch File (`start_ssh_tunnel.bat`)

Create `C:\Users\yourname\.ssh\start_ssh_tunnel.bat`:

```bat
@echo off

REM Start Elasticsearch in background
start /b "" "C:\Users\yourname\Downloads\elasticsearch-9.0.1-windows-x86_64\elasticsearch-9.0.1\bin\elasticsearch.bat"

REM Wait for Elasticsearch to start
timeout /t 15 >nul

REM Start reverse SSH tunnel in background
start /b "" ssh -i "C:\Users\yourname\.ssh\privatesshkey" -N -R 9200:localhost:9200 ubuntu@<VM_PUBLIC_IP> >> "C:\Users\yourname\Documents\ssh_tunnel_log.txt" 2>&1
```

- Adjust all paths, usernames, and `<VM_PUBLIC_IP>` as needed.

### VBS File (`start_ssh_tunnel.vbs`)

Create `C:\Users\yourname\.ssh\start_ssh_tunnel.vbs`:

```vbscript
Set WshShell = CreateObject("WScript.Shell")
WshShell.Run """C:\Users\yourname\.ssh\start_ssh_tunnel.bat""", 0
```

- The `, 0` argument hides the window.

---

## Step 5: Automate with Task Scheduler

1. Open **Task Scheduler**.
2. Create a new task:
   - **Trigger:** At log on (or at startup)
   - **Action:** Start a program → point to your `.vbs` file
   - **Settings:**
     - Run whether user is logged on or not
     - Restart if the task fails
     - If already running, restart the task
3. This ensures Elasticsearch and the tunnel start automatically and restart if stopped.

---

## Step 6: Test from Ubuntu VM

On your VM, run:

```bash
curl -k -u elastic:<your-password> https://localhost:9200
```

You should get a JSON response from Elasticsearch.

Check the tunnel is listening:

```bash
sudo ss -tulnp | grep 9200
```

Expected:  
`tcp   LISTEN ... 127.0.0.1:9200 ... users:(("sshd",pid=...,fd=...))`

---

## Daily Restart Checklist

1. **Start Elasticsearch** (if not automated):

   ```cmd
   cd C:\Users\yourname\Downloads\elasticsearch-9.0.1-windows-x86_64\elasticsearch-9.0.1\bin
   .\elasticsearch.bat
   ```

   > Do not close this window if running manually.

2. **Test from VM**:
   ```bash
   curl -k -u elastic:<your-password> https://localhost:9200
   ```
   > If JSON is returned, everything is working.

---

## Troubleshooting

- Check `ssh_tunnel_log.txt` for SSH errors.
- Ensure all paths, usernames, and SSH keys are correct.
- To stop, end the processes in Task Manager or disable the scheduled task.

---

**This setup provides a seamless, background process for running Elasticsearch and maintaining the reverse SSH tunnel, keeping your workflow clean and automated.**

---

# Step-by-Step: Telegraf → Nginx Logs → Elasticsearch

## Objective

Collect and parse Nginx access and error logs using Telegraf, then send the metrics to Elasticsearch for visualization (e.g., via Kibana or Grafana).

---

## Prerequisites

- Nginx installed and running with access & error logs in `/var/log/nginx/`
- Elasticsearch running with authentication enabled (on HTTPS)
- Telegraf installed on the same VM as Nginx logs

---

## 1. Configure Nginx Logs

Verify Nginx log files are accessible and located at:

- Access logs: `/var/log/nginx/access.log`
- Error logs: `/var/log/nginx/error.log`

---

## 2. Configure Telegraf Input Plugin for Tail Logs

Edit your Telegraf config file (usually `/etc/telegraf/telegraf.conf`) and add the following blocks (replace `YOUR_PUBLIC_IP_OR_DOMAIN` with your actual VM IP or domain):

```toml
# Tail Nginx access log
[[inputs.tail]]
  files = ["/var/log/nginx/access.log"]
  data_format = "grok"
  grok_patterns = ["%{COMBINED_LOG_FORMAT}"]
  name_override = "nginx_access_log"
  tags = { server_name = "YOUR_PUBLIC_IP_OR_DOMAIN" }

# Tail Nginx error log
[[inputs.tail]]
  files = ["/var/log/nginx/error.log"]
  data_format = "grok"
  grok_patterns = ["%{NGINX_ERROR_LOG}"]
  name_override = "nginx_error_log"
  tags = { server_name = "YOUR_PUBLIC_IP_OR_DOMAIN" }
```

**Important notes:**

- Use `COMBINED_LOG_FORMAT` for access logs — it covers the common Nginx access log format.
- Use `NGINX_ERROR_LOG` (note underscore, not camel case) for error logs.
- You must add these custom grok patterns since `NGINX_ERROR_LOG` is not a default pattern in Telegraf.

---

## 3. Define Custom Grok Pattern for NGINX_ERROR_LOG

Add this pattern to your Telegraf configuration under the global `grok_patterns` setting, or create a separate patterns file and reference it via:

```toml
[grok]
patterns = '''
NGINX_ERROR_LOG %{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:message}
'''
```

Or, create a file `/etc/telegraf/patterns/nginx_patterns` with the above content, and then in your `inputs.tail` section add:

```toml
grok_custom_patterns = "/etc/telegraf/patterns/nginx_patterns"
```

---

## 4. Address Permissions & Capabilities for Ping Plugin (Optional)

If you use the ping input plugin, you might get errors like:

```
ping failed: permission changes required, enable CAP_NET_RAW capabilities
```

Fix by running:

```bash
sudo setcap cap_net_raw+ep $(which ping)
```

---

## 5. Configure Telegraf Output Plugin to Elasticsearch

Add or update the Elasticsearch output plugin in your Telegraf config:

```toml
[[outputs.elasticsearch]]
  urls = ["https://localhost:9200"]  # or your Elasticsearch URL
  username = "elastic"                # your elasticsearch username
  password = "YOUR_PASSWORD"          # your elasticsearch password
  insecure_skip_verify = true         # if using self-signed SSL certs
  index_name = "telegraf-nginx-logs-%Y.%m.%d"
```

Note: Adjust URL, credentials, and SSL settings as per your Elasticsearch setup.

---

## 6. Testing Telegraf Configuration Locally

Run this command to test your Telegraf config and see parsed metrics and logs without sending to outputs:

```bash
sudo telegraf --config /etc/telegraf/telegraf.conf --test
```

If you want to filter just the tail plugin:

```bash
sudo telegraf --config /etc/telegraf/telegraf.conf --input-filter tail --test
```

---

## 7. Starting & Enabling Telegraf Service

```bash
sudo systemctl restart telegraf
sudo systemctl enable telegraf
sudo systemctl status telegraf
```

Check logs if needed:

```bash
sudo journalctl -u telegraf -f
```

---

## 8. Verify Data in Elasticsearch

Use Kibana or curl to verify data is arriving:

```bash
curl -u elastic:YOUR_PASSWORD "https://localhost:9200/telegraf-nginx-logs-*/_search?pretty" --insecure
```

You should see documents containing fields parsed from Nginx logs.

---

## Troubleshooting Common Errors

| Error message                            | Cause                                          | Fix                                                            |
| ---------------------------------------- | ---------------------------------------------- | -------------------------------------------------------------- |
| no pattern found for %{NGINXERRORLOG}    | Incorrect grok pattern name or missing pattern | Use NGINX_ERROR_LOG and define custom pattern as shown         |
| ping failed: permission changes required | Missing Linux capability for ping              | Run `sudo setcap cap_net_raw+ep $(which ping)`                 |
| missing authentication credentials (401) | Elasticsearch security enabled, missing auth   | Provide correct username & password in output plugin           |
| curl: (60) SSL certificate problem       | Self-signed SSL cert                           | Use `--insecure` flag or `insecure_skip_verify=true` in config |
