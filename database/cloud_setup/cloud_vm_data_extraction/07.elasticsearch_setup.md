<!--Just yesterday, I learnt that using a relational database managmeent system isnt the best choice for managing application logs and a time series databases exist for this reason. So, I will now create a separate database to collect application logs. I will be using elasticsearch server engine, and for data visualization, I will primairly use Grafana for system level metrics, and then use Tableau/PowerBI for business level metrics-->

# Elasticsearch 9.0.1 Installation & Reverse SSH Tunnel Setup

This guide describes how to install Elasticsearch 9.0.1 locally on Windows, and how to make it accessible from a remote Ubuntu VM using a reverse SSH tunnel. It also covers automating the startup of both Elasticsearch and the tunnel in the background using Task Scheduler.

---

## Overview

- **Purpose:** Collect application logs using Elasticsearch, visualize system metrics with Grafana, and business metrics with Tableau/PowerBI.
- **Setup:** Local Elasticsearch on Windows, accessible from a remote Ubuntu VM via reverse SSH tunnel.

---

## System Requirements

- Operating System: Windows 11, macOS Ventura, Ubuntu 22.04, etc.
- Java: Bundled with Elasticsearch 9.0.1
- Recommended RAM: Minimum 4GB

---

## Step 1: Download & Install Elasticsearch

1. Download from: https://www.elastic.co/downloads/elasticsearch  
   (e.g., `elasticsearch-9.0.1-windows-x86_64.zip`)
2. Extract to: `C:\Elastic\elasticsearch-9.0.1` (or your preferred directory)

---

## Step 2: Start Elasticsearch

1. Open a terminal or PowerShell window.
2. Change directory to the `bin` folder:
   ```cmd
   cd C:\Elastic\elasticsearch-9.0.1\bin
   .\elasticsearch.bat
   ```
3. On first startup, note the generated `elastic` user password.

> Elasticsearch 9.x+ starts with security enabled (HTTPS, authentication).

---

## Step 3: Access Elasticsearch

- URL: https://localhost:9200
- Use your browser or an API client (e.g., Postman, curl).
- Default username: `elastic`
- Password: Shown in terminal on first startup.

Example verification:

```cmd
curl -k -u elastic:<your-password> https://localhost:9200
```

Expected: JSON response with cluster info.

---

## Step 4: Set Up Reverse SSH Tunnel (Windows → Ubuntu VM)

This allows your Ubuntu VM to access Elasticsearch running on your Windows machine.

### Batch File (`start_ssh_tunnel.bat`)

Create `C:\Users\yourname\.ssh\start_ssh_tunnel.bat`:

```bat
@echo off

REM Start Elasticsearch in background
start /b "" "C:\Users\yourname\Downloads\elasticsearch-9.0.1-windows-x86_64\elasticsearch-9.0.1\bin\elasticsearch.bat"

REM Wait for Elasticsearch to start
timeout /t 15 >nul

REM Start reverse SSH tunnel in background
start /b "" ssh -i "C:\Users\yourname\.ssh\privatesshkey" -N -R 9200:localhost:9200 ubuntu@<VM_PUBLIC_IP> >> "C:\Users\yourname\Documents\ssh_tunnel_log.txt" 2>&1
```

- Adjust all paths, usernames, and `<VM_PUBLIC_IP>` as needed.

### VBS File (`start_ssh_tunnel.vbs`)

Create `C:\Users\yourname\.ssh\start_ssh_tunnel.vbs`:

```vbscript
Set WshShell = CreateObject("WScript.Shell")
WshShell.Run """C:\Users\yourname\.ssh\start_ssh_tunnel.bat""", 0
```

- The `, 0` argument hides the window.

---

## Step 5: Automate with Task Scheduler

1. Open **Task Scheduler**.
2. Create a new task:
   - **Trigger:** At log on (or at startup)
   - **Action:** Start a program → point to your `.vbs` file
   - **Settings:**
     - Run whether user is logged on or not
     - Restart if the task fails
     - If already running, restart the task
3. This ensures Elasticsearch and the tunnel start automatically and restart if stopped.

---

## Step 6: Test from Ubuntu VM

On your VM, run:

```bash
curl -k -u elastic:<your-password> https://localhost:9200
```

You should get a JSON response from Elasticsearch.

Check the tunnel is listening:

```bash
sudo ss -tulnp | grep 9200
```

Expected:  
`tcp   LISTEN ... 127.0.0.1:9200 ... users:(("sshd",pid=...,fd=...))`

---

## Daily Restart Checklist

1. **Start Elasticsearch** (if not automated):

   ```cmd
   cd C:\Users\yourname\Downloads\elasticsearch-9.0.1-windows-x86_64\elasticsearch-9.0.1\bin
   .\elasticsearch.bat
   ```

   > Do not close this window if running manually.

2. **Test from VM**:
   ```bash
   curl -k -u elastic:<your-password> https://localhost:9200
   ```
   > If JSON is returned, everything is working.

---

## Troubleshooting

- Check `ssh_tunnel_log.txt` for SSH errors.
- Ensure all paths, usernames, and SSH keys are correct.
- To stop, end the processes in Task Manager or disable the scheduled task.

---

**This setup provides a seamless, background process for running Elasticsearch and maintaining the reverse SSH tunnel, keeping your workflow clean and automated.**

---

# Step-by-Step: Telegraf → Nginx Logs → Elasticsearch

## Objective

Collect and parse Nginx access and error logs using Telegraf, then send the metrics to Elasticsearch for visualization (e.g., via Kibana or Grafana).

---

## Prerequisites

- Nginx installed and running with access & error logs in `/var/log/nginx/`
- Elasticsearch running with authentication enabled (on HTTPS)
- Telegraf installed on the same VM as Nginx logs

---

## 1. Configure Nginx Logs

Verify Nginx log files are accessible and located at:

- Access logs: `/var/log/nginx/access.log`
- Error logs: `/var/log/nginx/error.log`

---

## 2. Configure Telegraf Input Plugin for Tail Logs

Edit your Telegraf config file (usually `/etc/telegraf/telegraf.conf`) and add the following blocks (replace `YOUR_PUBLIC_IP_OR_DOMAIN` with your actual VM IP or domain):

```toml
# Tail Nginx access log
[[inputs.tail]]
  files = ["/var/log/nginx/access.log"]
  data_format = "grok"
  grok_patterns = ["%{COMBINED_LOG_FORMAT}"]
  name_override = "nginx_access_log"
  tags = { server_name = "YOUR_PUBLIC_IP_OR_DOMAIN" }

# Tail Nginx error log
[[inputs.tail]]
  files = ["/var/log/nginx/error.log"]
  data_format = "grok"
  grok_patterns = ["%{NGINX_ERROR_LOG}"]
  name_override = "nginx_error_log"
  tags = { server_name = "YOUR_PUBLIC_IP_OR_DOMAIN" }
```

**Important notes:**

- Use `COMBINED_LOG_FORMAT` for access logs — it covers the common Nginx access log format.
- Use `NGINX_ERROR_LOG` (note underscore, not camel case) for error logs.
- You must add these custom grok patterns since `NGINX_ERROR_LOG` is not a default pattern in Telegraf.

---

## 3. Define Custom Grok Pattern for NGINX_ERROR_LOG

Add this pattern to your Telegraf configuration under the global `grok_patterns` setting, or create a separate patterns file and reference it via:

```toml
[grok]
patterns = '''
NGINX_ERROR_LOG %{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:message}
'''
```

Or, create a file `/etc/telegraf/patterns/nginx_patterns` with the above content, and then in your `inputs.tail` section add:

```toml
grok_custom_patterns = "/etc/telegraf/patterns/nginx_patterns"
```

---

## 4. Address Permissions & Capabilities for Ping Plugin (Optional)

If you use the ping input plugin, you might get errors like:

```
ping failed: permission changes required, enable CAP_NET_RAW capabilities
```

Fix by running:

```bash
sudo setcap cap_net_raw+ep $(which ping)
```

---

## 5. Configure Telegraf Output Plugin to Elasticsearch

Add or update the Elasticsearch output plugin in your Telegraf config:

```toml
[[outputs.elasticsearch]]
  urls = ["https://localhost:9200"]  # or your Elasticsearch URL
  username = "elastic"                # your elasticsearch username
  password = "YOUR_PASSWORD"          # your elasticsearch password
  insecure_skip_verify = true         # if using self-signed SSL certs
  index_name = "telegraf-nginx-logs-%Y.%m.%d"
```

Note: Adjust URL, credentials, and SSL settings as per your Elasticsearch setup.

---

## 6. Testing Telegraf Configuration Locally

Run this command to test your Telegraf config and see parsed metrics and logs without sending to outputs:

```bash
sudo telegraf --config /etc/telegraf/telegraf.conf --test
```

If you want to filter just the tail plugin:

```bash
sudo telegraf --config /etc/telegraf/telegraf.conf --input-filter tail --test
```

---

## 7. Starting & Enabling Telegraf Service

```bash
sudo systemctl restart telegraf
sudo systemctl enable telegraf
sudo systemctl status telegraf
```

Check logs if needed:

```bash
sudo journalctl -u telegraf -f
```

---

## 8. Verify Data in Elasticsearch

Use Kibana or curl to verify data is arriving:

```bash
curl -u elastic:YOUR_PASSWORD "https://localhost:9200/telegraf-nginx-logs-*/_search?pretty" --insecure
```

You should see documents containing fields parsed from Nginx logs.

---

## Troubleshooting Common Errors

| Error message                            | Cause                                          | Fix                                                            |
| ---------------------------------------- | ---------------------------------------------- | -------------------------------------------------------------- |
| no pattern found for %{NGINXERRORLOG}    | Incorrect grok pattern name or missing pattern | Use NGINX_ERROR_LOG and define custom pattern as shown         |
| ping failed: permission changes required | Missing Linux capability for ping              | Run `sudo setcap cap_net_raw+ep $(which ping)`                 |
| missing authentication credentials (401) | Elasticsearch security enabled, missing auth   | Provide correct username & password in output plugin           |
| curl: (60) SSL certificate problem       | Self-signed SSL cert                           | Use `--insecure` flag or `insecure_skip_verify=true` in config |

---

# Another problem

Telegraf didnt have permission to access nginx logs, realized so when there was no data being sent to Elastic search specificto nginc logs.

run: sudo usermod -aG adm telegraf
added the telegraf user to the adm group, which is the group that typically owns /var/log/nginx/\*.log on Ubuntu. This allowed Telegraf to read the Nginx log files without changing their ownership.

Fixed grok issue

## Why Nginx Error Logs Weren’t Showing Up in Grafana (and How It Was Solved)

### Root Cause

Telegraf was not parsing any lines from `/var/log/nginx/error.log` because it was starting at the end of the file and only watching for new lines appended after startup. The grok pattern was correct, but since no new lines were being written, Telegraf had nothing to parse or forward to Elasticsearch.

### How It Was Solved

Set `from_beginning = true` in the Telegraf `[[inputs.tail]]` block for error logs.  
This forced Telegraf to process all existing lines in `/var/log/nginx/error.log` (not just new lines).

**Example:**

- Restarted Telegraf.
- Telegraf then parsed the existing error log lines, outputting them to both the file and Elasticsearch.
- Verified parsing with `telegraf --test` and confirmed data appeared in Elasticsearch and Grafana.

**Summary:**  
The main issue was that Telegraf was not reading any lines from the error log because it started at the end of the file. Setting `from_beginning = true` allowed Telegraf to process all existing log lines, making error logs visible in Grafana.

---

## Note on Log File Truncation (Rotation)

Log file truncation (or rotation) is another important scenario to consider when using Telegraf’s `inputs.tail` plugin.

- When Nginx rotates or truncates its log files (e.g., via `logrotate`), the log file may be emptied or replaced.
- If Telegraf is tailing the file and it gets truncated, Telegraf may lose its place and, depending on configuration, might not read new lines written after truncation.
- By default, Telegraf tries to handle truncation by re-reading from the beginning of the file if it detects the file size has shrunk.

**Best Practice:**

- For production, ensure your log rotation (`logrotate`) is configured to use the `copytruncate` option, or restart Telegraf after rotation to avoid missing logs.
- Monitor Telegraf logs for messages about file truncation or inode changes.

**Summary:**

- Log truncation (rotation) can cause Telegraf to miss log lines if not handled properly.
- Telegraf is designed to detect truncation and re-read, but you should test your setup after log rotation to ensure no data loss.
- Setting `from_beginning = true` helps on initial startup, but doesn’t affect behavior after truncation—Telegraf will only read new lines after the truncation event.
