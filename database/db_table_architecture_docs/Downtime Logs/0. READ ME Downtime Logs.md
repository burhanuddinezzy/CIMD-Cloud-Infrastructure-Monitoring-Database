# Downtime Logs

This table records and tracks server downtime events, crucial for reliability monitoring, SLA compliance, and root cause analysis. By capturing the start and end times of downtime, its cause, and its impact on service-level agreements (SLAs), this table helps optimize system uptime, reduce failures, and improve response strategies.
<!----------------------------------------------------------------------------------------------->
<!----------------------------------------------------------------------------------------------->
**How Downtime Detection Works (and how my alert_config table fits in):**

- CPU at 0% idle (i.e., 100% busy) for an extended period usually indicates a server is stuck or overloaded, potentially leading to unresponsiveness or "soft" downtime. This is a common alert.

- CPU at 0% (total usage) while the server should be active (e.g., network activity is also zero, no Nginx requests) would often indicate the server is frozen or powered off/unreachable. This is also a strong downtime indicator.

- "Web server status is not active" means Nginx is not responding to requests, or its stub_status endpoint is unreachable. This is a very direct indicator of web server downtime.

It's about Defining Conditions:
Your alert_config table is where you (or your custom alerting script) would define the precise conditions for what constitutes "downtime." These conditions can be:

Single Metric Threshold:
- "If nginx.status.active_connections drops to 0 for more than 5 minutes."
- "If system.cpu.idle is consistently below 5% for 10 minutes."
- "If the server hasn't reported any metrics in the last 2 minutes (a 'no data' alert)."

Combined Metric Thresholds:
- "If nginx.connections.active is 0 AND system.network.bytes_recv is 0 AND system.cpu.idle is 100% (server possibly crashed)."

Log Pattern Detection:
- "If the count of 'critical' or 'panic' messages in nginx_error_log exceeds 5 in a 1-minute window."
- "If more than 10 consecutive requests in nginx_access_log result in 5xx status codes."

External Checks (Reachability):
- "If an external ping or HTTP check to YOUR_VM_PUBLIC_IP on port 80 fails for 3 consecutive checks." (This typically requires a separate "Uptime Monitor" service, not Telegraf itself).

How Your alert_config and Custom Script Would Work:
Your alert_config table would store the rules for these scenarios. Your custom alerting script (running periodically) would:

Query the relevant data (from Elasticsearch for logs, and potentially PostgreSQL for metrics or a separate Prometheus instance).

Evaluate these conditions against the incoming data.

If a condition (or combination of conditions) is met for a defined duration, it would then insert an entry into your downtime_logs table, specifying the start_time, downtime_cause (based on the triggered rule), etc.

It would also need logic to detect when the condition clears and then update the end_time in the downtime_logs table.

So, yes, it just needs one or more metrics (or log patterns) hitting certain thresholds for a specified duration to trigger an entry into your downtime_logs table. The beauty is that you get to define what those thresholds and combinations are in your alert_config table.
<!----------------------------------------------------------------------------------------------->
<!----------------------------------------------------------------------------------------------->
### **Data Points (Columns) – Purpose, Thought Process, and Data Type**

- **`server_id` (UUID, Foreign Key)**
    
    **Purpose**: Links the downtime event to the affected server.
    
    **How I Thought of Including It**: Essential for tracking downtime per server.
    
    **Why I Thought of Including It**: Helps in identifying unreliable servers and planning maintenance.
    
    **Data Type Used & Why**: `UUID` as it matches `server_id` in the **Server Metrics** table for joins.
    
- **`start_time` (TIMESTAMP)**
    
    **Purpose**: Marks the beginning of a downtime event.
    
    **How I Thought of Including It**: Needed to calculate total downtime duration.
    
    **Why I Thought of Including It**: Helps in analyzing when downtimes commonly occur.
    
    **Data Type Used & Why**: `TIMESTAMP` for precise event tracking.
    
- **`end_time` (TIMESTAMP, Nullable)**
    
    **Purpose**: Marks when the downtime event ended.
    
    **How I Thought of Including It**: Required to measure downtime duration.
    
    **Why I Thought of Including It**: Identifies servers with prolonged outages.
    
    **Data Type Used & Why**: `TIMESTAMP NULL` (null if still down, otherwise records end time).
    
- **`downtime_duration_minutes` (INTEGER, Generated Column)**
    
    **Purpose**: Stores total downtime duration in minutes.
    
    **How I Thought of Including It**: Reduces query complexity when calculating downtime.
    
    **Why I Thought of Including It**: Directly provides downtime length for SLA calculations.
    
    **Data Type Used & Why**: `INTEGER GENERATED ALWAYS AS (EXTRACT(EPOCH FROM (end_time - start_time)) / 60) STORED`, ensuring automatic calculation.
    
- **`downtime_cause` (VARCHAR(255))**
    
    **Purpose**: Describes why the downtime occurred (e.g., hardware failure, software crash).
    
    **How I Thought of Including It**: Needed for diagnosing recurring issues.
    
    **Why I Thought of Including It**: Helps in preventive maintenance and risk analysis.
    
    **Data Type Used & Why**: `VARCHAR(255)`, balancing storage efficiency and readability.
    
- **`sla_tracking` (BOOLEAN)**
    
    **Purpose**: Indicates whether this downtime event impacted the SLA.
    
    **How I Thought of Including It**: SLAs require strict uptime monitoring.
    
    **Why I Thought of Including It**: Helps in ensuring contractual obligations are met.
    
    **Data Type Used & Why**: `BOOLEAN`, as it’s a simple yes/no condition.
    
- **`incident_id` (UUID, Foreign Key, Nullable)**
    
    **Purpose**: Links the downtime event to an incident report in the `incident_management` table.
    
    **How I Thought of Including It**: Needed for connecting downtime events with resolution workflows.
    
    **Why I Thought of Including It**: Helps in tracking remediation steps and identifying recurring failures.
    
    **Data Type Used & Why**: `UUID NULL`, allowing optional linkage to an incident record.
    
- **`is_planned` (BOOLEAN)**
    
    **Purpose**: Differentiates between **planned maintenance** and **unexpected outages**.
    
    **How I Thought of Including It**: Planned maintenance doesn’t count against SLA violations.
    
    **Why I Thought of Including It**: Helps in SLA tracking and reporting accurate downtime statistics.
    
    **Data Type Used & Why**: `BOOLEAN`, as it’s a simple true/false condition.
    
- **`recovery_action` (VARCHAR(255))**
    
    **Purpose**: Stores the action taken to restore the server (e.g., reboot, hardware replacement).
    
    **How I Thought of Including It**: Helps in identifying effective recovery strategies.
    
    **Why I Thought of Including It**: Allows post-mortem analysis to improve uptime.
    
    **Data Type Used & Why**: `VARCHAR(255)`, providing flexibility for storing descriptions.
    
- **Example of Stored Data**
    
    | downtime_id | server_id | start_time | end_time | downtime_duration_minutes | downtime_cause | sla_tracking |
    | --- | --- | --- | --- | --- | --- | --- |
    | `d1a2b3` | `s1x2y3` | 2024-01-30 10:15:00 | 2024-01-30 10:45:00 | 30 | "Power failure" | TRUE |
    | `d4e5f6` | `s7m8n9` | 2024-01-30 15:30:00 | NULL | NULL | "Database crash" | FALSE |

## Dive Into Details
 - [**How It Interacts with Other Tables**](How%20It%20Interacts%20with%20Other%20Tables.md)

 - [**What Queries Would Be Used?**](What%20Queries%20Would%20Be%20Used.md)

 - [**Alternative Approaches**](Alternative%20Approaches.md)

 - [**Real-World Use Cases**](Real-World%20Use%20Cases.md)

 - [**Performance Considerations & Scalability**](Performance%20Considerations%20&%20Scalability.md)

 - [**Query Optimization Techniques**](Query%20Optimization%20Techniques.md)

 - [**Handling Large-Scale Data**](Handling%20Large-Scale%20Data.md)

 - [**Data Retention & Cleanup**](Data%20Retention%20&%20Cleanup.md)

 - [**Security & Compliance**](Security%20&%20Compliance.md)

 - [**Alerting & Automation**](Alerting%20&%20Automation.md)

 - [**How You Tested & Validated Data Integrity**](How%20You%20Tested%20&%20Validated%20Data%20Integrity.md)

 - [**Thought Process Behind Decisions**](Thought%20Process%20Behind%20Decisions.md)
